{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Learning for Sequential (Text) data\n",
    "This notebook contains all the necessary code to perform the experiments for this exercise! Start by reading the `ReadMe.md` to have an setup ready. Afterward, you can start with this notebook! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu using PyTorch 2.4.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import nltk\n",
    "import torch\n",
    "import flwr as fl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from nltk.lm import Vocabulary\n",
    "from nltk.corpus import reuters\n",
    "from typing import Dict\n",
    "from collections import OrderedDict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from flwr.common import NDArrays, Scalar\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on {DEVICE} using PyTorch {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section defines all the possible hyperparameters that can be used to configure the model. Just update the values to your desired configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset hyperparameters\n",
    "MAX_LEN = 60\n",
    "\n",
    "# Model hyperparameters\n",
    "EMBED_SIZE = 128\n",
    "HIDDEN_SIZE = 256\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.5\n",
    "\n",
    "# Training hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.01\n",
    "NUM_EPOCHS = 100\n",
    "NUM_CLIENTS = 15\n",
    "\n",
    "# General hyperparameters\n",
    "RANDOM_STATE = 42\n",
    "VERBOSE = True\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "Next, we define the datastructure, load the dataset and perform the necessary pre-processing. We begin by defining the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReutersDataset(Dataset):\n",
    "    def __init__(self, texts, labels, maxlen):\n",
    "        self.texts = [text[:maxlen] for text in texts]\n",
    "        self.labels = labels\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = torch.tensor(self.texts[idx], dtype=torch.long)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return text, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterward, we define all the necessary methods to load and pre-process the data. Therefore, we performed tokenization, stopword removal, building up a vocabulary, and encoded the tokens into a numerical representation on our own. For this we used NLTK and scikit-learn respectively. Furthermore, we incorporated a max length into our feature to reduce further computational resources. Additionally, we added padding to the text-feature to unify it, as the input for the model. For this, we used pytorch. Lastly, we label encode the target feature with scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _collate_fn(batch, vocab):\n",
    "    texts, labels = zip(*batch)\n",
    "    texts_padded = pad_sequence(texts, batch_first=True, padding_value=vocab[\"<pad>\"])\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    return texts_padded, labels\n",
    "\n",
    "\n",
    "def _remove_stopwords(text):\n",
    "    stop = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "    return (\n",
    "        pd.Series(text)\n",
    "        .str.lower()\n",
    "        .replace(r\"[^\\w\\s]\", \"\", regex=True)\n",
    "        .apply(nltk.word_tokenize)\n",
    "        .apply(\n",
    "            lambda sentence: \" \".join([word for word in sentence if word not in stop])\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def _process_labels(labels):\n",
    "    return pd.Series(labels).apply(lambda x: x[0] if x else \"unknown\")\n",
    "\n",
    "\n",
    "def load_dataset(maxlen):\n",
    "    nltk.download(\"reuters\")\n",
    "    nltk.download(\"stopwords\")\n",
    "    nltk.download(\"punkt\")\n",
    "\n",
    "    # Load documents and their categories\n",
    "    documents = reuters.fileids()\n",
    "    categories = [reuters.categories(fileid) for fileid in documents]\n",
    "\n",
    "    # Load document content\n",
    "    data = [reuters.raw(fileid) for fileid in documents]\n",
    "\n",
    "    text = _remove_stopwords(data)\n",
    "    tokens = [nltk.word_tokenize(sentence) for sentence in text]\n",
    "\n",
    "    # Flatten the list of tokens for vocabulary creation\n",
    "    flat_tokens = [token for sentence in tokens for token in sentence]\n",
    "    vocab = Vocabulary(flat_tokens)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    labels = label_encoder.fit_transform(_process_labels(categories))\n",
    "\n",
    "    # Add a padding token to the vocabulary\n",
    "    vocab.update([\"<pad>\"])\n",
    "    encoded_texts = [[vocab[token] for token in sentence] for sentence in tokens]\n",
    "\n",
    "    # Apply maxlen to encoded texts\n",
    "    encoded_texts = [text[:maxlen] for text in encoded_texts]\n",
    "\n",
    "    encoded_df = pd.DataFrame(\n",
    "        {\n",
    "            \"text\": encoded_texts,\n",
    "            \"category\": labels,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return encoded_df, vocab, label_encoder\n",
    "\n",
    "\n",
    "def create_dataloader(text, labels, vocab, maxlen, shuffle = True):\n",
    "    dataset = ReutersDataset(text.tolist(), labels.tolist(), maxlen)\n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=shuffle,\n",
    "        collate_fn=lambda x: _collate_fn(x, vocab),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to call the `load_dataset` method with the desired max length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     /Users/maxkleinegger/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/maxkleinegger/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/maxkleinegger/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "df, vocab, label_encoder = load_dataset(MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we split the dataset into training and testing sets, based on a 80:20 ratio and transform them into PyTorch DataLoader objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df[\"text\"], df[\"category\"], test_size=0.2, random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = create_dataloader(train_texts, train_labels, vocab, MAX_LEN)\n",
    "test_loader = create_dataloader(test_texts, test_labels, vocab, MAX_LEN, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State-of-the-art baseline\n",
    "This section implements and evaluates a state-of-the-art bidirectional LSTM model for text classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "First, we define the model itself with its necessary parameters. Afterward, we implement a method \n",
    "- to train the model based on provided dataset.\n",
    "- evaluate the model based on a provided dataset by computing the utility metrics accuracy, precision, recall and f1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BidirectionalLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, output_size, padding_idx, embed_size=128, hidden_size=256, num_layers=2, dropout=0.5):\n",
    "        super(BidirectionalLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=padding_idx)\n",
    "        self.rnn = nn.LSTM(\n",
    "            embed_size,\n",
    "            hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        _, (hidden, _) = self.rnn(embedded)\n",
    "        hidden = torch.cat((hidden[-2], hidden[-1]), dim=1)\n",
    "        out = self.dropout(hidden)\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, num_epochs, optimizer, device=DEVICE, verbose=False):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        epoch_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for texts, labels in train_loader:\n",
    "            texts, labels = texts.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(texts)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device=DEVICE, verbose=False):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "\n",
    "    total, correct = 0, 0\n",
    "    total_loss = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for texts, labels in test_loader:\n",
    "            texts, labels = texts.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(texts)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    total_loss /= len(test_loader)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    precision = precision_score(all_labels, all_predictions, average='weighted', zero_division=1)\n",
    "    recall = recall_score(all_labels, all_predictions, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Test Loss: {total_loss:.4f}, Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "        print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "    return total_loss, accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "In this section, we train the model, based on `NUM_EPOCHS` specified. We however, evaluate the model after each epoch and save the results to a prior specified file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_centralised(model, train_loader, test_loader, epochs, lr, momentum=0.9, device=DEVICE, verbose=False):\n",
    "    optim = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    train_model(model, train_loader, epochs, optim, device)\n",
    "    loss, accuracy, precision, recall, f1 = evaluate_model(model, test_loader, device)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Accuracy: {accuracy:.4f}, Loss: {loss:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "    return accuracy, loss, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the file to save the results to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"results/results_baseline.csv\"\n",
    "os.makedirs(\"results\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the bidirectional LSTM, based on the provided hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BidirectionalLSTM(\n",
    "    vocab_size=len(vocab),\n",
    "    output_size= len(label_encoder.classes_),\n",
    "    padding_idx=vocab[\"<pad>\"],\n",
    "    embed_size=EMBED_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=DROPOUT\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we need to start the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "epochs_count = 0\n",
    "for epochs in range(1):\n",
    "    epochs_count += 1\n",
    "    acc, loss, precision, recall, f1 = run_centralised(model, train_loader, test_loader, epochs=1, lr=LEARNING_RATE, verbose=False)\n",
    "    with open(file_path, \"a\") as file:\n",
    "        file.write(f\"{epochs_count},{acc},{loss},{precision},{recall},{f1}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM to be federated\n",
    "This section implements and evaluates the model we want to federate. Futher we implement the server and client for the federation process and start a simulation to evaluate its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "First, we define the model itself with its necessary parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        output_size,\n",
    "        padding_idx,\n",
    "        embed_size=128,\n",
    "        hidden_size=256,\n",
    "        num_layers=2,\n",
    "        dropout=0.5,\n",
    "    ):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=padding_idx)\n",
    "        self.rnn = nn.LSTM(\n",
    "            embed_size,\n",
    "            hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=False,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        _, (hidden, _) = self.rnn(embedded)\n",
    "        hidden = hidden[-1]\n",
    "        out = self.dropout(hidden)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "To have a value to compare to, we train and evaluate the model based on `NUM_EPOCHS` specified. The reason for this is to see how well the model overall performs and furthermore have a upper bound for our federated model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define the file to save the results to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"results/results_no_fed.csv\"\n",
    "os.makedirs(\"results\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the uni-directional LSTM, based on the provided hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(\n",
    "    vocab_size=len(vocab),\n",
    "    output_size= len(label_encoder.classes_),\n",
    "    padding_idx=vocab[\"<pad>\"],\n",
    "    embed_size=EMBED_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=DROPOUT\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the bidirectional LSTM, based on the provided hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "epochs_count = 0\n",
    "for epochs in range(1):\n",
    "    epochs_count += epochs\n",
    "    acc, loss, precision, recall, f1 = run_centralised(model, train_loader, test_loader, epochs=1, lr=LEARNING_RATE, verbose=False)\n",
    "    with open(file_path, \"a\") as file:\n",
    "       file.write(f\"{epochs_count},{acc},{loss},{precision},{recall},{f1}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Federated LSTM\n",
    "Now we deal with federating the model and data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partition data\n",
    "We start by partitioning the data into `num_partitions`. This is crucial for further work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_dataset(train_loader, test_loader, vocab, num_partitions, batch_size, val_ratio=0.1):\n",
    "    # Extract dataset from DataLoader\n",
    "    train_dataset = train_loader.dataset\n",
    "    test_dataset = test_loader.dataset\n",
    "\n",
    "    # Calculate partition lengths\n",
    "    num_images = len(train_dataset)\n",
    "    partition_len = [num_images // num_partitions] * num_partitions\n",
    "    partition_len[-1] += (\n",
    "        num_images % num_partitions\n",
    "    )  # Add remainder to the last partition\n",
    "\n",
    "    trainsets = random_split(\n",
    "        train_dataset, partition_len, torch.Generator().manual_seed(2023)\n",
    "    )\n",
    "\n",
    "    # Create DataLoaders with train+val support\n",
    "    trainloaders = []\n",
    "    valloaders = []\n",
    "    for trainset in trainsets:\n",
    "        num_total = len(trainset)\n",
    "        num_val = int(val_ratio * num_total)\n",
    "        num_train = num_total - num_val\n",
    "\n",
    "        train_subset, val_subset = random_split(trainset, [num_train, num_val], torch.Generator().manual_seed(2023))\n",
    "\n",
    "        trainloaders.append(DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=0, collate_fn=lambda x: _collate_fn(x, vocab)))\n",
    "        valloaders.append(DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=lambda x: _collate_fn(x, vocab)))\n",
    "\n",
    "    # Create DataLoader for the test set\n",
    "    testloader = DataLoader(test_dataset, batch_size=128, collate_fn=lambda x: _collate_fn(x, vocab))\n",
    "\n",
    "    return trainloaders, valloaders, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloaders, valloaders, testloader = partition_dataset(train_loader, test_loader, vocab, NUM_CLIENTS, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualization\n",
    "We also added a small visualization of the distribution of classes within on partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_loader.dataset\n",
    "partition_indices = train_partition.indices\n",
    "labels = [train_dataset[i][1].item() for i in partition_indices]\n",
    "\n",
    "# Visualize histogram\n",
    "plt.hist(labels, bins=len(label_encoder.classes_), edgecolor='black')\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Number of images\")\n",
    "plt.title(\"Class Labels Distribution for Reuters Dataset\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Client\n",
    "Next, we implement the client based on the Flower library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReutersClient(fl.client.NumPyClient):\n",
    "    def __init__(self, vocab_size, output_size, padding_idx, embed_size, hidden_size, num_layers, dropout, device, learning_rate, trainloader, valloader) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "        self.device = device\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = LSTM(\n",
    "            vocab_size=vocab_size,\n",
    "            output_size= output_size,\n",
    "            padding_idx=padding_idx,\n",
    "            embed_size=embed_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout\n",
    "        ).to(device)\n",
    "\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "        self.model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        optim = torch.optim.SGD(self.model.parameters(), lr=self.learning_rate, momentum=0.9)\n",
    "        train_model(model=self.model, train_loader=self.trainloader, num_epochs=1, optimizer=optim, device=self.device, verbose=False,)\n",
    "        return self.get_parameters({}), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        loss, accuracy, precision, recall, f1 = evaluate_model(self.model, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And add some additional function to create and evaluate the client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evaluate_fn(vocab_size, output_size, padding_idx, embed_size, hidden_size, num_layers, dropout, device, testloader):\n",
    "    def evaluate_fn(server_round, parameters, config):\n",
    "        model = LSTM(\n",
    "            vocab_size=vocab_size,\n",
    "            output_size= output_size,\n",
    "            padding_idx=padding_idx,\n",
    "            embed_size=embed_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout\n",
    "        ).to(device)\n",
    "\n",
    "        params_dict = zip(model.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "        model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "        loss, accuracy, precision, recall, f1 = evaluate_model(\n",
    "            model, testloader\n",
    "        )\n",
    "        return loss, {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "    return evaluate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_client_fn(vocab_size, output_size, padding_idx, embed_size, hidden_size, num_layers, dropout, device, learning_rate, trainloaders, valloaders):\n",
    "    def client_fn(cid: str):\n",
    "        return ReutersClient(vocab_size, output_size, padding_idx, embed_size, hidden_size, num_layers, dropout, device, learning_rate, trainloader=trainloaders[int(cid)], valloader=valloaders[int(cid)]).to_client()\n",
    "\n",
    "    return client_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Server\n",
    "Lastly, we configure the aggregating strategy for the server and define the number of clients via the `NUM_CLIENTS` parameter. We further use all models to train and evaluate on all models available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=1, \n",
    "    fraction_evaluate=1,  \n",
    "    min_available_clients=NUM_CLIENTS, \n",
    "    evaluate_fn=get_evaluate_fn(len(vocab), len(label_encoder.classes_), vocab[\"<pad>\"], EMBED_SIZE, HIDDEN_SIZE, NUM_LAYERS, DROPOUT, DEVICE, testloader)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_fn_callback = generate_client_fn(len(vocab), len(label_encoder.classes_), vocab[\"<pad>\"], EMBED_SIZE, HIDDEN_SIZE, NUM_LAYERS, DROPOUT, DEVICE, LEARNING_RATE, trainloaders, valloaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training\n",
    "Next, we start the simulation of our federated ml model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = fl.simulation.start_simulation(\n",
    "    client_fn=client_fn_callback,\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=1),\n",
    "    strategy=strategy,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Results\n",
    "Lastly, we save the results to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for i in range(len(history.metrics_centralized['accuracy'])):\n",
    "    loss = history.losses_centralized[i][1]\n",
    "    epoch = history.metrics_centralized['accuracy'][i][0]\n",
    "    accuracy = history.metrics_centralized['accuracy'][i][1]\n",
    "    precision = history.metrics_centralized['precision'][i][1]\n",
    "    recall = history.metrics_centralized['recall'][i][1]\n",
    "    f1 = history.metrics_centralized['f1'][i][1]\n",
    "    \n",
    "    rows.append({\n",
    "        'epoch_nr': epoch,\n",
    "        'accuracy': accuracy,\n",
    "        \"loss\": loss,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    })\n",
    "\n",
    "df_metrics = pd.DataFrame(rows)\n",
    "df_metrics.to_csv(f\"results/results_federated_{NUM_CLIENTS}_clients.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
