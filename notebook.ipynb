{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Learning for Sequential (Text) data\n",
    "This notebook contains all the necessary code to perform the experiments for this exercise! Start by reading the `ReadMe.md` to have an setup ready. Afterward, you can start with this notebook! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxkleinegger/Desktop/test/speml.nosync/federated-text-classification/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-08-01 00:31:11,033\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu using PyTorch 2.4.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import nltk\n",
    "import torch\n",
    "import flwr as fl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from nltk.lm import Vocabulary\n",
    "from nltk.corpus import reuters\n",
    "from typing import Dict\n",
    "from collections import OrderedDict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from flwr.common import NDArrays, Scalar\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on {DEVICE} using PyTorch {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section defines all the possible hyperparameters that can be used to configure the model. Just update the values to your desired configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset hyperparameters\n",
    "MAX_LEN = 60\n",
    "\n",
    "# Model hyperparameters\n",
    "EMBED_SIZE = 128\n",
    "HIDDEN_SIZE = 256\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.5\n",
    "\n",
    "# Training hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.01\n",
    "NUM_EPOCHS = 100\n",
    "NUM_CLIENTS = 15\n",
    "\n",
    "# General hyperparameters\n",
    "RANDOM_STATE = 42\n",
    "VERBOSE = True\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "Next, we define the datastructure, load the dataset and perform the necessary pre-processing. We begin by defining the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReutersDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset for Reuters text classification.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, texts, labels, maxlen):\n",
    "        self.texts = [text[:maxlen] for text in texts]\n",
    "        self.labels = labels\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the number of samples.\"\"\"\n",
    "        \n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Returns the text and label at the given index as tensors.\"\"\"\n",
    "\n",
    "        text = torch.tensor(self.texts[idx], dtype=torch.long)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return text, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterward, we define all the necessary methods to load and pre-process the data. Therefore, we performed tokenization, stopword removal, building up a vocabulary, and encoded the tokens into a numerical representation on our own. For this we used NLTK and scikit-learn respectively. Furthermore, we incorporated a max length into our feature to reduce further computational resources. Additionally, we added padding to the text-feature to unify it, as the input for the model. For this, we used pytorch. Lastly, we label encode the target feature with scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _collate_fn(batch, vocab):\n",
    "    \"\"\"\n",
    "    Custom collate function for padding text sequences and converting labels to tensors.\n",
    "    This function pads text sequences to the same length and converts both texts and labels\n",
    "    into PyTorch tensors.\n",
    "    \"\"\"\n",
    "    texts, labels = zip(*batch)\n",
    "    texts_padded = pad_sequence(texts, batch_first=True, padding_value=vocab[\"<pad>\"])\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    return texts_padded, labels\n",
    "\n",
    "\n",
    "def _remove_stopwords(text):\n",
    "    \"\"\"\n",
    "    Removes stopwords from the given text.\n",
    "    This function tokenizes the text, removes English stopwords, and returns the cleaned text.\n",
    "    \"\"\"\n",
    "    stop = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "    return (\n",
    "        pd.Series(text)\n",
    "        .str.lower()\n",
    "        .replace(r\"[^\\w\\s]\", \"\", regex=True)\n",
    "        .apply(nltk.word_tokenize)\n",
    "        .apply(\n",
    "            lambda sentence: \" \".join([word for word in sentence if word not in stop])\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def _process_labels(labels):\n",
    "    \"\"\"\n",
    "    Processes and normalizes labels from a list of lists to a single label or 'unknown'.\n",
    "    This function converts labels to a single label if available, otherwise returns 'unknown'.\n",
    "    \"\"\"\n",
    "    return pd.Series(labels).apply(lambda x: x[0] if x else \"unknown\")\n",
    "\n",
    "\n",
    "def load_dataset(maxlen):\n",
    "    \"\"\"\n",
    "    Loads and preprocesses the Reuters dataset: Downloads necessary NLTK corpora, loads documents and categories, \n",
    "    removes stopwords, tokenizes text, creates vocabulary, and encodes texts and labels.\n",
    "    \"\"\"\n",
    "    nltk.download(\"reuters\")\n",
    "    nltk.download(\"stopwords\")\n",
    "    nltk.download(\"punkt\")\n",
    "\n",
    "    # Load documents and their categories\n",
    "    documents = reuters.fileids()\n",
    "    categories = [reuters.categories(fileid) for fileid in documents]\n",
    "\n",
    "    # Load document content\n",
    "    data = [reuters.raw(fileid) for fileid in documents]\n",
    "\n",
    "    text = _remove_stopwords(data)\n",
    "    tokens = [nltk.word_tokenize(sentence) for sentence in text]\n",
    "\n",
    "    # Flatten the list of tokens for vocabulary creation\n",
    "    flat_tokens = [token for sentence in tokens for token in sentence]\n",
    "    vocab = Vocabulary(flat_tokens)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    labels = label_encoder.fit_transform(_process_labels(categories))\n",
    "\n",
    "    # Add a padding token to the vocabulary\n",
    "    vocab.update([\"<pad>\"])\n",
    "    encoded_texts = [[vocab[token] for token in sentence] for sentence in tokens]\n",
    "\n",
    "    # Apply maxlen to encoded texts\n",
    "    encoded_texts = [text[:maxlen] for text in encoded_texts]\n",
    "\n",
    "    encoded_df = pd.DataFrame(\n",
    "        {\n",
    "            \"text\": encoded_texts,\n",
    "            \"category\": labels,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return encoded_df, vocab, label_encoder\n",
    "\n",
    "\n",
    "def create_dataloader(text, labels, vocab, maxlen, shuffle=True):\n",
    "    \"\"\"\n",
    "    Creates a DataLoader for the dataset. Initializes a ReutersDataset and wraps it in a DataLoader with specified batch size and\n",
    "    optional shuffling. Uses a custom collate function for padding and tensor conversion.\n",
    "    \"\"\"\n",
    "    dataset = ReutersDataset(text.tolist(), labels.tolist(), maxlen)\n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=shuffle,\n",
    "        collate_fn=lambda x: _collate_fn(x, vocab),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to call the `load_dataset` method with the desired max length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     /Users/maxkleinegger/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/maxkleinegger/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/maxkleinegger/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "df, vocab, label_encoder = load_dataset(MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we split the dataset into training and testing sets, based on a 80:20 ratio and transform them into PyTorch DataLoader objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df[\"text\"], df[\"category\"], test_size=0.2, random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = create_dataloader(train_texts, train_labels, vocab, MAX_LEN)\n",
    "test_loader = create_dataloader(test_texts, test_labels, vocab, MAX_LEN, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State-of-the-art baseline\n",
    "This section implements and evaluates a state-of-the-art bidirectional LSTM model for text classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "First, we define the model itself with its necessary parameters. Afterward, we implement a method \n",
    "- to train the model based on provided dataset.\n",
    "- evaluate the model based on a provided dataset by computing the utility metrics accuracy, precision, recall and f1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BidirectionalLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    A bidirectional LSTM model for sequence classification.\n",
    "\n",
    "    Args:\n",
    "        vocab_size (int): Size of the vocabulary.\n",
    "        output_size (int): Number of output classes.\n",
    "        padding_idx (int): Padding index for the embedding layer.\n",
    "        embed_size (int, optional): Size of the embedding vectors (default: 128).\n",
    "        hidden_size (int, optional): Number of hidden units in the LSTM (default: 256).\n",
    "        num_layers (int, optional): Number of LSTM layers (default: 2).\n",
    "        dropout (float, optional): Dropout rate applied to LSTM outputs (default: 0.5).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, output_size, padding_idx, embed_size=128, hidden_size=256, num_layers=2, dropout=0.5):\n",
    "        super(BidirectionalLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=padding_idx)\n",
    "        self.rnn = nn.LSTM(\n",
    "            embed_size,\n",
    "            hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        _, (hidden, _) = self.rnn(embedded)\n",
    "        hidden = torch.cat((hidden[-2], hidden[-1]), dim=1)\n",
    "        out = self.dropout(hidden)\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, num_epochs, optimizer, device=DEVICE, verbose=False):\n",
    "    \"\"\"\n",
    "    Trains the model for a specified number of epochs.\n",
    "    \"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        epoch_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for texts, labels in train_loader:\n",
    "            texts, labels = texts.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(texts)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss / len(train_loader):.4f}, Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device=DEVICE, verbose=False):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the test dataset. The function calculates and returns loss, accuracy, precision, recall\n",
    "    and F1 score for the model's predictions on the test data.\n",
    "    \"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "\n",
    "    total, correct = 0, 0\n",
    "    total_loss = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for texts, labels in test_loader:\n",
    "            texts, labels = texts.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(texts)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    total_loss /= len(test_loader)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    precision = precision_score(all_labels, all_predictions, average='weighted', zero_division=1)\n",
    "    recall = recall_score(all_labels, all_predictions, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Test Loss: {total_loss:.4f}, Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "        print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "    return total_loss, accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "In this section, we train the model, based on `NUM_EPOCHS` specified. We however, evaluate the model after each epoch and save the results to a prior specified file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_centralised(model, train_loader, test_loader, epochs, lr, momentum=0.9, device=DEVICE, verbose=False):\n",
    "    \"\"\" \n",
    "    Trains and evaluates the model using centralized training.\n",
    "    \"\"\"\n",
    "    optim = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    train_model(model, train_loader, epochs, optim, device)\n",
    "    loss, accuracy, precision, recall, f1 = evaluate_model(model, test_loader, device)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Accuracy: {accuracy:.4f}, Loss: {loss:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "    return accuracy, loss, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the file to save the results to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"results/results_baseline.csv\"\n",
    "os.makedirs(\"results\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the bidirectional LSTM, based on the provided hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BidirectionalLSTM(\n",
    "    vocab_size=len(vocab),\n",
    "    output_size= len(label_encoder.classes_),\n",
    "    padding_idx=vocab[\"<pad>\"],\n",
    "    embed_size=EMBED_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=DROPOUT\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we need to start the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "epochs_count = 0\n",
    "for epochs in range(1):\n",
    "    epochs_count += 1\n",
    "    acc, loss, precision, recall, f1 = run_centralised(model, train_loader, test_loader, epochs=1, lr=LEARNING_RATE, verbose=False)\n",
    "    with open(file_path, \"a\") as file:\n",
    "        file.write(f\"{epochs_count},{acc},{loss},{precision},{recall},{f1}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM to be federated\n",
    "This section implements and evaluates the model we want to federate. Futher we implement the server and client for the federation process and start a simulation to evaluate its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "First, we define the model itself with its necessary parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    A single-layer LSTM model for text classification.\n",
    "\n",
    "    Args:\n",
    "        vocab_size (int): Size of the vocabulary.\n",
    "        output_size (int): Number of output classes.\n",
    "        padding_idx (int): Padding index for the embedding layer.\n",
    "        embed_size (int, optional): Size of the embedding vectors (default: 128).\n",
    "        hidden_size (int, optional): Number of hidden units in the LSTM (default: 256).\n",
    "        num_layers (int, optional): Number of LSTM layers (default: 2).\n",
    "        dropout (float, optional): Dropout rate applied to LSTM outputs (default: 0.5).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        output_size,\n",
    "        padding_idx,\n",
    "        embed_size=128,\n",
    "        hidden_size=256,\n",
    "        num_layers=2,\n",
    "        dropout=0.5,\n",
    "    ):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=padding_idx)\n",
    "        self.rnn = nn.LSTM(\n",
    "            embed_size,\n",
    "            hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=False,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        _, (hidden, _) = self.rnn(embedded)\n",
    "        hidden = hidden[-1]\n",
    "        out = self.dropout(hidden)\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "To have a value to compare to, we train and evaluate the model based on `NUM_EPOCHS` specified. The reason for this is to see how well the model overall performs and furthermore have a upper bound for our federated model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define the file to save the results to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"results/results_no_fed.csv\"\n",
    "os.makedirs(\"results\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the uni-directional LSTM, based on the provided hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(\n",
    "    vocab_size=len(vocab),\n",
    "    output_size= len(label_encoder.classes_),\n",
    "    padding_idx=vocab[\"<pad>\"],\n",
    "    embed_size=EMBED_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=DROPOUT\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the bidirectional LSTM, based on the provided hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "epochs_count = 0\n",
    "for epochs in range(1):\n",
    "    epochs_count += epochs\n",
    "    acc, loss, precision, recall, f1 = run_centralised(model, train_loader, test_loader, epochs=1, lr=LEARNING_RATE, verbose=False)\n",
    "    with open(file_path, \"a\") as file:\n",
    "       file.write(f\"{epochs_count},{acc},{loss},{precision},{recall},{f1}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Federated LSTM\n",
    "Now we deal with federating the model and data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partition data\n",
    "We start by partitioning the data into `num_partitions`. This is crucial for further work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_dataset(train_loader, test_loader, vocab, num_partitions, batch_size, val_ratio=0.1):\n",
    "    \"\"\" \n",
    "    Partitions the training dataset into multiple subsets and creates DataLoaders for training, validation, and testing.\n",
    "    \"\"\"\n",
    "    # Extract dataset from DataLoader\n",
    "    train_dataset = train_loader.dataset\n",
    "    test_dataset = test_loader.dataset\n",
    "\n",
    "    # Calculate partition lengths\n",
    "    num_images = len(train_dataset)\n",
    "    partition_len = [num_images // num_partitions] * num_partitions\n",
    "    partition_len[-1] += (\n",
    "        num_images % num_partitions\n",
    "    )  # Add remainder to the last partition\n",
    "\n",
    "    trainsets = random_split(\n",
    "        train_dataset, partition_len, torch.Generator().manual_seed(2023)\n",
    "    )\n",
    "\n",
    "    # Create DataLoaders with train+val support\n",
    "    trainloaders = []\n",
    "    valloaders = []\n",
    "    for trainset in trainsets:\n",
    "        num_total = len(trainset)\n",
    "        num_val = int(val_ratio * num_total)\n",
    "        num_train = num_total - num_val\n",
    "\n",
    "        train_subset, val_subset = random_split(trainset, [num_train, num_val], torch.Generator().manual_seed(2023))\n",
    "\n",
    "        trainloaders.append(DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=0, collate_fn=lambda x: _collate_fn(x, vocab)))\n",
    "        valloaders.append(DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=lambda x: _collate_fn(x, vocab)))\n",
    "\n",
    "    # Create DataLoader for the test set\n",
    "    testloader = DataLoader(test_dataset, batch_size=128, collate_fn=lambda x: _collate_fn(x, vocab))\n",
    "\n",
    "    return trainloaders, valloaders, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloaders, valloaders, testloader = partition_dataset(train_loader, test_loader, vocab, NUM_CLIENTS, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualization\n",
    "We also added a small visualization of the distribution of classes within on partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_partition = trainloaders[1].dataset\n",
    "partition_indices = train_partition.indices\n",
    "\n",
    "plt.hist([train_partition.dataset[idx][1].item() for idx in partition_indices], bins=len(label_encoder.classes_), edgecolor=\"black\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Number of articles\")\n",
    "plt.title(\"Class Labels Distribution for Reuters Dataset\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Client\n",
    "Next, we implement the client based on the Flower library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReutersClient(fl.client.NumPyClient):\n",
    "    \"\"\"\n",
    "    A Federated Learning client for training and evaluating an LSTM model on the Reuters dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, output_size, padding_idx, embed_size, hidden_size, num_layers, dropout, device, learning_rate, trainloader, valloader) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "        self.device = device\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = LSTM(\n",
    "            vocab_size=vocab_size,\n",
    "            output_size= output_size,\n",
    "            padding_idx=padding_idx,\n",
    "            embed_size=embed_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout\n",
    "        ).to(device)\n",
    "\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        \"\"\" \n",
    "        Sets the model parameters from the provided list.\n",
    "        \"\"\"\n",
    "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "        self.model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        \"\"\"\n",
    "        Returns the model parameters as a list of numpy arrays.\n",
    "        \"\"\"\n",
    "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        \"\"\"\n",
    "        Trains the model on the local training data with the given parameters.\n",
    "        \"\"\"\n",
    "        self.set_parameters(parameters)\n",
    "        optim = torch.optim.SGD(self.model.parameters(), lr=self.learning_rate, momentum=0.9)\n",
    "        train_model(model=self.model, train_loader=self.trainloader, num_epochs=1, optimizer=optim, device=self.device, verbose=False,)\n",
    "        return self.get_parameters({}), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        \"\"\"\n",
    "        Evaluates the model on the local validation data with the given parameters.\n",
    "        \"\"\"\n",
    "        self.set_parameters(parameters)\n",
    "        loss, accuracy, precision, recall, f1 = evaluate_model(self.model, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And add some additional function to create and evaluate the client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evaluate_fn(vocab_size, output_size, padding_idx, embed_size, hidden_size, num_layers, dropout, device, testloader):\n",
    "    \"\"\"\n",
    "    Creates an evaluation function for federated learning.\n",
    "    \"\"\"\n",
    "    def evaluate_fn(server_round, parameters, config):\n",
    "        model = LSTM(\n",
    "            vocab_size=vocab_size,\n",
    "            output_size= output_size,\n",
    "            padding_idx=padding_idx,\n",
    "            embed_size=embed_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout\n",
    "        ).to(device)\n",
    "\n",
    "        params_dict = zip(model.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "        model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "        loss, accuracy, precision, recall, f1 = evaluate_model(\n",
    "            model, testloader\n",
    "        )\n",
    "        return loss, {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "    return evaluate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_client_fn(vocab_size, output_size, padding_idx, embed_size, hidden_size, num_layers, dropout, device, learning_rate, trainloaders, valloaders):\n",
    "    \"\"\"\n",
    "    Creates a client function for federated learning.\n",
    "    \"\"\"\n",
    "    def client_fn(cid: str):\n",
    "        return ReutersClient(vocab_size, output_size, padding_idx, embed_size, hidden_size, num_layers, dropout, device, learning_rate, trainloader=trainloaders[int(cid)], valloader=valloaders[int(cid)]).to_client()\n",
    "\n",
    "    return client_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Server\n",
    "Lastly, we configure the aggregating strategy for the server and define the number of clients via the `NUM_CLIENTS` parameter. We further use all models to train and evaluate on all models available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=1, \n",
    "    fraction_evaluate=1,  \n",
    "    min_available_clients=NUM_CLIENTS, \n",
    "    evaluate_fn=get_evaluate_fn(len(vocab), len(label_encoder.classes_), vocab[\"<pad>\"], EMBED_SIZE, HIDDEN_SIZE, NUM_LAYERS, DROPOUT, DEVICE, testloader)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_fn_callback = generate_client_fn(len(vocab), len(label_encoder.classes_), vocab[\"<pad>\"], EMBED_SIZE, HIDDEN_SIZE, NUM_LAYERS, DROPOUT, DEVICE, LEARNING_RATE, trainloaders, valloaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training\n",
    "Next, we start the simulation of our federated ml model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = fl.simulation.start_simulation(\n",
    "    client_fn=client_fn_callback,\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=NUM_EPOCHS),\n",
    "    strategy=strategy,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Results\n",
    "Lastly, we save the results to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for i in range(len(history.metrics_centralized['accuracy'])):\n",
    "    loss = history.losses_centralized[i][1]\n",
    "    epoch = history.metrics_centralized['accuracy'][i][0]\n",
    "    accuracy = history.metrics_centralized['accuracy'][i][1]\n",
    "    precision = history.metrics_centralized['precision'][i][1]\n",
    "    recall = history.metrics_centralized['recall'][i][1]\n",
    "    f1 = history.metrics_centralized['f1'][i][1]\n",
    "    \n",
    "    rows.append({\n",
    "        'epoch_nr': epoch,\n",
    "        'accuracy': accuracy,\n",
    "        \"loss\": loss,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    })\n",
    "\n",
    "df_metrics = pd.DataFrame(rows)\n",
    "df_metrics.to_csv(f\"results/results_federated_{NUM_CLIENTS}_clients.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
