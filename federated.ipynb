{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on mps using PyTorch 2.3.1\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchtext\n",
    "\n",
    "torchtext.disable_torchtext_deprecation_warning()\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "DEVICE = (\n",
    "    torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    ")\n",
    "print(f\"Training on {DEVICE} using PyTorch {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to /Users/gabriel/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gabriel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/Users/gabriel/federated-text-classification/.venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from dataset import load_dataset, to_dataloader\n",
    "\n",
    "\n",
    "NUM_CLIENTS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "df, vocab, label_encoder = load_dataset()\n",
    "\n",
    "\n",
    "def split_dataset():\n",
    "    train, test = train_test_split(df, test_size=0.1, random_state=42)\n",
    "\n",
    "    partitions = np.array_split(train, NUM_CLIENTS)\n",
    "\n",
    "    # Create train/val for each partition and wrap it into DataLoader\n",
    "    trainloaders: list[DataLoader] = []\n",
    "    valloaders: list[DataLoader] = []\n",
    "    for partition_id in range(NUM_CLIENTS):\n",
    "        partition = partitions[partition_id]\n",
    "\n",
    "        train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "            partition[\"text\"],\n",
    "            partition[\"category\"],\n",
    "            test_size=0.2,\n",
    "            random_state=42,\n",
    "        )\n",
    "\n",
    "        train_loader = to_dataloader(train_texts, train_labels, vocab)\n",
    "        test_loader = to_dataloader(test_texts, test_labels, vocab)\n",
    "\n",
    "        trainloaders.append(train_loader)\n",
    "        valloaders.append(test_loader)\n",
    "\n",
    "    testloader = to_dataloader(test[\"text\"], test[\"category\"], vocab)\n",
    "    return trainloaders, valloaders, testloader\n",
    "\n",
    "\n",
    "trainloaders, valloaders, test_loader = split_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    num_epochs: int,\n",
    "    verbose=False,\n",
    "):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for texts, labels in train_loader:\n",
    "            texts, labels = texts.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            outputs = model(texts)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "\n",
    "def test(model: nn.Module, test_loader: DataLoader):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for texts, labels in test_loader:\n",
    "            texts, labels = texts.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            outputs = model(texts)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    loss /= len(test_loader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr.client import Client, NumPyClient\n",
    "\n",
    "from text_rnn import TextRNN\n",
    "\n",
    "class FlowerClient(NumPyClient):\n",
    "    def __init__(self, net: nn.Module, trainloader: DataLoader, valloader: DataLoader):\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config) -> list[np.ndarray]:\n",
    "        return [val.cpu().numpy() for _, val in self.net.state_dict().items()]\n",
    "    \n",
    "    def _set_parameters(self, parameters: list[np.ndarray]):\n",
    "        params_dict = zip(self.net.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "        self.net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self._set_parameters(parameters)\n",
    "\n",
    "        train(self.net, self.trainloader, num_epochs=1)\n",
    "\n",
    "        return self.get_parameters(config), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self._set_parameters(parameters)\n",
    "\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "    \n",
    "\n",
    "def create_client(cid: str) -> Client:\n",
    "    vocab_size = len(vocab)\n",
    "    output_size = len(label_encoder.classes_)\n",
    "    model = TextRNN(vocab_size, output_size, padding_idx=vocab[\"<pad>\"]).to(DEVICE)\n",
    "\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "\n",
    "    return FlowerClient(model, trainloader, valloader).to_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=5, no round_timeout\n",
      "2024-07-25 10:03:32,702\tINFO worker.py:1752 -- Started a local Ray instance.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'memory': 16480411648.0, 'node:127.0.0.1': 1.0, 'node:__internal_head__': 1.0, 'object_store_memory': 2147483648.0, 'CPU': 10.0}\n",
      "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 10 actors\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
      "\u001b[33m(raylet)\u001b[0m /Users/gabriel/federated-text-classification/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "\u001b[33m(raylet)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(ClientAppActor pid=23795)\u001b[0m /Users/gabriel/federated-text-classification/.venv/lib/python3.9/site-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
      "\u001b[36m(ClientAppActor pid=23795)\u001b[0m /!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "\u001b[36m(ClientAppActor pid=23795)\u001b[0m Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "\u001b[36m(ClientAppActor pid=23795)\u001b[0m   warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "\u001b[36m(ClientAppActor pid=23795)\u001b[0m /Users/gabriel/federated-text-classification/.venv/lib/python3.9/site-packages/torchtext/utils.py:4: UserWarning: \n",
      "\u001b[36m(ClientAppActor pid=23795)\u001b[0m /!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "\u001b[36m(ClientAppActor pid=23795)\u001b[0m Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "\u001b[36m(ClientAppActor pid=23795)\u001b[0m   warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Evaluating initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[33m(raylet)\u001b[0m /Users/gabriel/federated-text-classification/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m   warnings.warn(\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    }
   ],
   "source": [
    "from flwr.server.strategy import FedAvg\n",
    "from flwr.server import ServerConfig\n",
    "from flwr.simulation import start_simulation\n",
    "\n",
    "strategy = FedAvg(\n",
    "    fraction_fit=1.0,  # Sample 100% of available clients for training\n",
    "    fraction_evaluate=0.5,  # Sample 50% of available clients for evaluation\n",
    "    min_fit_clients=10,  # Never sample less than 10 clients for training\n",
    "    min_evaluate_clients=5,  # Never sample less than 5 clients for evaluation\n",
    "    min_available_clients=10,  # Wait until all 10 clients are available\n",
    ")\n",
    "\n",
    "client_resources = {\"num_cpus\": 1, \"num_gpus\": 0.0}\n",
    "if DEVICE.type == \"cuda\":\n",
    "    # here we are assigning an entire GPU for each client.\n",
    "    client_resources = {\"num_cpus\": 1, \"num_gpus\": 1.0}\n",
    "\n",
    "# Start simulation\n",
    "start_simulation(\n",
    "    client_fn=create_client,\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    config=ServerConfig(num_rounds=5),\n",
    "    strategy=strategy,\n",
    "    client_resources=client_resources,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
